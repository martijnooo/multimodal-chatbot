# Multimodal Chatbot with RAG, Memory, and Streamlit

This project is a **multimodal AI chatbot** built with **Streamlit**, **LangChain/LangGraph-style agents**, **Pinecone RAG**, **Whisper transcription**, **SQLite document registry**, and **LangSmith tracing**. It supports:

* Audio file ingestion
* Automatic transcription (Whisper)
* Chunking & summarization for RAG
* Pinecone vector storage & retrieval
* Time-based queries on audio
* Multi-turn memory via thread IDs
* Per-user document registry using SQLite
* A clean Streamlit UX

---

## ğŸš€ Features

### ğŸ”Š Audio Processing Pipeline

When a user uploads an audio file (`mp3`, `wav`, `m4a`):

1. Transcription using Whisper
2. Chunking of transcript by timestamps
3. Summarization of entire transcript
4. Chunks + summary stored in Pinecone
5. Document metadata stored in SQLite (`user_id`, filename, summary, type)
6. Context returned to the chat agent

### ğŸ“š Retrieval (RAG)

* Vector search using **Pinecone**
* Supports **metadata filters** (start time, end time, source)
* Supports **full-text queries**
* Metadata-only queries use a neutral placeholder vector

### ğŸ§  Multi-turn Memory

* Implemented via `config={configurable: {thread_id: "..."}}`
* File uploads insert contextual system messages into the conversation

### ğŸ’¾ SQLite Document Registry

Each uploaded file is recorded in a local SQLite database.

* User ID
* File source
* File type
* Summary
* Timestamp

Custom tools allow the agent to:

* List a user's uploaded documents
* Retrieve RAG data

### ğŸ§ª LangSmith Integration

* Full tracing enabled
* Automatic logging of pipeline execution, chain calls, and tool invocations

---

## ğŸ“ Project Structure

```
app/
â”‚
â”œâ”€â”€ app.py                     # Streamlit UI
â”œâ”€â”€ router.py                  # File routing based on mime type
â”‚
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ audio_pipeline.py      # Full audio â†’ RAG processing pipeline
â”‚   â”œâ”€â”€ image_pipeline.py
â”‚   â”œâ”€â”€ pdf_pipeline.py
â”‚   â””â”€â”€ text_pipeline.py
â”‚
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ audio.py               # Whisper transcription
â”‚   â”œâ”€â”€ chunking.py            # Time-based chunking
â”‚   â””â”€â”€ summarize.py           # Summary LLM calls
â”‚
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ base.py                # Pinecone setup + uploads
â”‚   â”œâ”€â”€ build_records.py       # Chunk + summary record builders
â”‚   â””â”€â”€ retrival.py            # Retrieval functions + tools
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ create.py              # Setup of the main agent
â”‚   â””â”€â”€ queries.py             # Memory-aware query execution
â”‚
â”œâ”€â”€ data_storage/
â”‚   â”œâ”€â”€ add_document.py        # Insert row into SQLite
â”‚   â””â”€â”€ list_documents.py      # Tool for agent to list user documents
â”‚
â””â”€â”€ database/
    â”œâ”€â”€ documents.db           # SQLite file
    â””â”€â”€ init.sql               # Optional schema
```

---

## âš™ï¸ Setup

### 1ï¸âƒ£ Clone & install

```bash
git clone <repo-url>
cd multimodal-chatbot
pip install -r requirements.txt
```

### 2ï¸âƒ£ Add your secrets to Streamlit

`.streamlit/secrets.toml`:

```toml
[openai]
api_key = "YOUR_OPENAI_KEY"

[langsmith]
api_key = "YOUR_LANGSMITH_KEY"
project = "your-project-name"
endpoint = "https://api.smith.langchain.com"
tracing = "true"
```

### 3ï¸âƒ£ Run the app

```bash
streamlit run app.py
```

---

## ğŸ“¡ File Processing Flow

```
User uploads â†’ router.py â†’ audio_pipeline â†’ Whisper
              â†“
              chunking â†’ build records â†’ Pinecone
              â†“
              SQLite document registry
              â†“
      Chat agent receives contextual system message
```

---

## ğŸ” RAG Query Flow

```
User question â†’ memory-aware query â†’ agent â†’ tools:
    - pinecone retrival tool
    - list_documents tool

Responses are enriched using RAG records & summaries.
```

---

## ğŸ§  Memory Handling

Uses LangChainâ€™s configurable thread IDs:

```python
agent.invoke({"messages": [...]}, config={"configurable": {"thread_id": "1"}})
```

This persists state across turns.

---

## ğŸ›  Utilities

### Clearing the local SQLite database

A helper exists to wipe the document registry for debugging.

### Debug Logging

All pipelines include `logger.info()` calls.

LangSmith provides full chain/tool visibility.

---

## ğŸ—ºï¸ Roadmap

* Add login system for per-user persistent documents
* Add PDF & text pipeline
* Improve time-based retrieval UX
* Add agent streaming
* Add summarization-on-query for long documents
* Add real user IDs instead of "user1"

---

## ğŸ¤ Contributing

PRs are welcome! If you want help restructuring the code, adding tests, or extending the pipeline, feel free to open an issue.

---

## ğŸ“„ License

MIT License.
